# version: '3.8'  # Явно указываем версию

# version: '3.8'

services:
  elasticsearch:
    image: docker.elastic.co/elasticsearch/elasticsearch:7.17.9
    container_name: elasticsearch
    environment:
      - discovery.type=single-node  # Исправлено
      - ES_JAVA_OPTS=-Xms512m -Xmx512m
      - cluster.routing.allocation.disk.threshold_enabled=false  # Отключаем проверку диска
    ports:
      - "9200:9200"
    volumes:
      - esdata:/usr/share/elasticsearch/data
    healthcheck:
      test: ["CMD", "curl", "-fsSL", "http://localhost:9200/_cluster/health?wait_for_status=yellow"]
      interval: 10s
      retries: 5
    networks:
      - kafka-network

  zookeeper:
    image: bitnami/zookeeper:latest
    container_name: zookeeper
    ports:
      - "2181:2181"
    environment:
      ALLOW_ANONYMOUS_LOGIN: "yes"
      ZOO_MAX_CLIENT_CNXNS: 60
    networks:
      - kafka-network
    restart: unless-stopped
    healthcheck:
      test: ["CMD-SHELL", "zkServer.sh status"]
      interval: 10s
      timeout: 5s
      retries: 3

  kafka:
    build:
      context: .
      dockerfile: Dockerfile.kafka
    container_name: kafka
    ports:
      - "9092:9092"
    environment:
      KAFKA_CFG_LISTENERS: PLAINTEXT://:9092
      KAFKA_CFG_ADVERTISED_LISTENERS: PLAINTEXT://kafka:9092
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      ALLOW_PLAINTEXT_LISTENER: "yes"
      KAFKA_HEAP_OPTS: "-Xmx1G -Xms1G"
    networks:
      - kafka-network
    depends_on:
      zookeeper:
        condition: service_healthy
    restart: unless-stopped
    volumes:
      - kafka-data:/bitnami/kafka

  db:
    image: postgres:13
    container_name: postgres
    restart: unless-stopped
    env_file:
      - postgres.env
    ports:
      - "5434:5432"
    volumes:
      - db-data:/var/lib/postgresql/data
      - ./initdb:/docker-entrypoint-initdb.d
      - nfs-data:/mnt/nfs_share
    networks:
      - kafka-network
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U postgres"]
      interval: 5s
      timeout: 5s
      retries: 5

  server:
    build: ./server
    container_name: server
    env_file:
      - server_config.env
    depends_on:
      db:
        condition: service_healthy
      kafka:
        condition: service_started
      elasticsearch:
        condition: service_healthy
    environment:
      PORT: 5000
      NODE_ENV: development
      ELASTICSEARCH_URL: http://elasticsearch:9200
    ports:
      - "5000:5000"
    volumes:
      - ./server:/app
      - nfs-data:/mnt/nfs_share
      - ./server/node_modules:/app/node_modules
    networks:
      - kafka-network
    restart: unless-stopped

    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:5000/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 10s

  reindex-cron:
    build: ./server
    env_file:
      - server_config.env
    environment:
      - ELASTICSEARCH_URL=http://elasticsearch:9200
      - NODE_ENV=development
    depends_on:
      - server
      - elasticsearch
      - db
    volumes:
      - ./server:/app
      - ./server/node_modules:/app/node_modules  # Монтируем локальные node_modules
    command: npm run reindex:cron
    networks:
      - kafka-network
    

  redis:
    image: redis:latest
    container_name: redis
    env_file:
      - redis.env
    ports:
      - "6379:6379"
    networks:
      - kafka-network
    restart: unless-stopped
    
  hasura:
    image: hasura/graphql-engine:v2.40.0
    container_name: hasura
    ports:
      - "8080:8080" # Порт прокинут: 8080 на хосте → 8080 в контейнере
    depends_on:
      db:
        condition: service_healthy
    env_file:
      - hasura.env
    networks:
      - kafka-network
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8080/healthz"]
      interval: 30s
      timeout: 10s
      retries: 3
  # В задницу.
  # hasura-migrations:
  #   image: hasura/graphql-engine:v2.40.0.cli-migrations
  #   volumes:
  #     - ./hasura:/hasura
  #   depends_on:
  #     hasura:
  #       condition: service_healthy
  #   env_file:
  #     - hasura.env
  #   command: >
  #     bash -c "
  #       until curl -s http://hasura:8080/healthz | grep -q 'OK'; do
  #         sleep 2
  #       done &&
  #       if [ ! -f /hasura/config.yaml ]; then
  #         hasura init --endpoint http://hasura:8080 --admin-secret $${HASURA_GRAPHQL_ADMIN_SECRET} --project /hasura
  #       fi &&
  #       hasura --project /hasura migrate apply --all &&
  #       hasura --project /hasura metadata apply &&
  #       hasura --project /hasura metadata export &&
  #       echo 'Migrations and metadata applied and exported!'
  #     "
  #   networks:
  #     - kafka-network
  
  s3-minio:
    build:
      context: .
      dockerfile: Dockerfile.minio
    container_name: s3-minio
    ports:
      - "9000:9000"
      - "9090:9090"
    env_file:
      - s3-minio.env
    environment:
      MINIO_BROWSER: "on"
      MINIO_SERVER_URL: "http://localhost:9000"
    command: server /data --console-address ":9090"
    volumes:
      - minio-data:/data
    networks:
      - kafka-network
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:9000/minio/health/live"]
      interval: 30s
      timeout: 5s
      retries: 3

  nfs-server:
    build:
      context: .
      dockerfile: Dockerfile.nfs
    container_name: nfs-server
    volumes:
      - nfs-data:/mnt/nfs_share
    privileged: true
    ports:
      - "2049:2049"
    networks:
      - kafka-network
    restart: unless-stopped
  service_ping:
    build:
      context: .
      dockerfile: Dockerfile.service_ping
    restart: always # Перезапускаемся пока идет конфигурация кафки
    environment:
      - KAFKA_BROKER=kafka:9092  # Адрес Kafka внутри Docker-сети
    depends_on:
      - kafka  # Убедитесь, что Kafka доступна перед запуском
    networks:
      - kafka-network
  

  # service_ollama:
  #   image: ollama/ollama:latest
  #   container_name: ollama
  #   ports:
  #     - "11434:11434"
  #   volumes:
  #     - ollama_data:/root/.ollama
  #   healthcheck:
  #     test: [ "CMD", "curl", "-f", "http://localhost:11434/api/tags" ]
  #     interval: 10s
  #     timeout: 5s
  #     retries: 5
  #     start_period: 30s
  
  #   networks:
  #     - kafka-network
  prometheus:
    image: prom/prometheus:latest
    container_name: prometheus
    volumes:
      - ./prometheus.yml:/etc/prometheus/prometheus.yml:ro
      - prometheus-data:/prometheus
    ports:
      - "9080:9080"  # Изменено: внешний порт 9080 мапится на внутренний 9090
    networks:
      - kafka-network
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "wget", "--quiet", "--tries=1", "--spider", "http://localhost:9090/-/healthy"]
      interval: 30s
      timeout: 10s
      retries: 3

  grafana:
    image: grafana/grafana:latest
    container_name: grafana
    env_file:
      - grafana.env  # Замените на свой пароль
    volumes:
      - grafana-data:/var/lib/grafana
    ports:
      - "3000:3000"
    networks:
      - kafka-network
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:3000/api/health"]
      interval: 30s
      timeout: 10s
      retries: 3
    depends_on:
      - prometheus

  postgres-exporter:
    image: prometheuscommunity/postgres-exporter:latest
    container_name: postgres-exporter
    environment:
      DATA_SOURCE_NAME: "postgresql://postgres:your_password@db:5432/postgres?sslmode=disable"  # Замените your_password
    ports:
      - "9187:9187"
    networks:
      - kafka-network
    depends_on:
      db:
        condition: service_healthy
    restart: unless-stopped

  redis-exporter:
    image: oliver006/redis_exporter:latest
    container_name: redis-exporter
    environment:
      REDIS_ADDR: "redis:6379"
      REDIS_PASSWORD: ""  # Укажите пароль, если он есть в redis.env
    ports:
      - "9121:9121"
    networks:
      - kafka-network
    depends_on:
      - redis
    restart: unless-stopped

networks:
  kafka-network:
    driver: bridge
    ipam:
      config:
        - subnet: 172.20.0.0/16

volumes:
  db-data:
  ollama_data:
  nfs-data:
  minio-data:
  kafka-data:
  esdata:
    driver: local
  zookeeper-data:
  prometheus-data:
    driver: local
  grafana-data:
    driver: local
  